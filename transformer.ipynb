{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 1.0000, 0.0000, 1.0000],\n",
      "         [0.8415, 0.5403, 0.0100, 0.9999]]])\n",
      "tensor([[[0.2848, 1.5087, 0.7941, 1.8575],\n",
      "         [1.0497, 0.5462, 0.8766, 1.8510]],\n",
      "\n",
      "        [[0.4574, 1.6655, 0.1240, 1.0548],\n",
      "         [1.4170, 1.2497, 1.0021, 1.8364]],\n",
      "\n",
      "        [[0.5931, 1.8079, 0.6458, 1.6025],\n",
      "         [0.8469, 0.5648, 0.4028, 1.7824]]])\n",
      "tensor([[[0.2848, 1.5087, 0.7941, 1.8575],\n",
      "         [1.0497, 0.5462, 0.8766, 1.8510]],\n",
      "\n",
      "        [[0.4574, 1.6655, 0.1240, 1.0548],\n",
      "         [1.4170, 1.2497, 1.0021, 1.8364]],\n",
      "\n",
      "        [[0.5931, 1.8079, 0.6458, 1.6025],\n",
      "         [0.8469, 0.5648, 0.4028, 1.7824]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class PositionEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self,hidden_dim,seq_len):\n",
    "        super().__init__()\n",
    "        # hidden_dim就是每个seq的编码长度\n",
    "        # 与X大小一致 其为seq_len,hidden_dim\n",
    "        self.encoding = torch.zeros(seq_len,hidden_dim)\n",
    "\n",
    "        pos = torch.arange(0,seq_len).float() #[seq_len]\n",
    "        pos = pos.unsqueeze(dim=1)\n",
    "        # 得到一个 [seq_len,1]\n",
    "\n",
    "        # 得到hidden_dim的索引i\n",
    "        _2i = torch.arange(0,hidden_dim,step=2).float()\n",
    "        # 2*i\n",
    "\n",
    "        self.encoding[:,0::2] = torch.sin(pos/(10000**(_2i/hidden_dim)))\n",
    "        self.encoding[:,1::2] = torch.cos(pos/(10000**(_2i/hidden_dim)))\n",
    "\n",
    "        # 此时encoding还没有加上batch_size的维度\n",
    "        self.encoding = self.encoding.unsqueeze(0)\n",
    "\n",
    "    def forward(self,X):\n",
    "\n",
    "        batch_size,seq_len,_ = X.shape\n",
    "        print(self.encoding)\n",
    "        return X + self.encoding[:,:seq_len,:]\n",
    "\n",
    "X = torch.rand(3,2,4)\n",
    "net = PositionEncoding(hidden_dim=4,seq_len=2)\n",
    "y = net(X)\n",
    "print(y)\n",
    "print(X+net.encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_embeddings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0membedding_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpadding_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_norm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnorm_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msparse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0m_weight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"A simple lookup table that stores embeddings of a fixed dictionary and size.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This module is often used to store word embeddings and retrieve them using indices.\u001b[0m\n",
      "\u001b[0;34m    The input to the module is a list of indices, and the output is the corresponding\u001b[0m\n",
      "\u001b[0;34m    word embeddings.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m        num_embeddings (int): size of the dictionary of embeddings\u001b[0m\n",
      "\u001b[0;34m        embedding_dim (int): the size of each embedding vector\u001b[0m\n",
      "\u001b[0;34m        padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the gradient;\u001b[0m\n",
      "\u001b[0;34m                                     therefore, the embedding vector at :attr:`padding_idx` is not updated during training,\u001b[0m\n",
      "\u001b[0;34m                                     i.e. it remains as a fixed \"pad\". For a newly constructed Embedding,\u001b[0m\n",
      "\u001b[0;34m                                     the embedding vector at :attr:`padding_idx` will default to all zeros,\u001b[0m\n",
      "\u001b[0;34m                                     but can be updated to another value to be used as the padding vector.\u001b[0m\n",
      "\u001b[0;34m        max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`\u001b[0m\n",
      "\u001b[0;34m                                    is renormalized to have norm :attr:`max_norm`.\u001b[0m\n",
      "\u001b[0;34m        norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.\u001b[0m\n",
      "\u001b[0;34m        scale_grad_by_freq (boolean, optional): If given, this will scale gradients by the inverse of frequency of\u001b[0m\n",
      "\u001b[0;34m                                                the words in the mini-batch. Default ``False``.\u001b[0m\n",
      "\u001b[0;34m        sparse (bool, optional): If ``True``, gradient w.r.t. :attr:`weight` matrix will be a sparse tensor.\u001b[0m\n",
      "\u001b[0;34m                                 See Notes for more details regarding sparse gradients.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Attributes:\u001b[0m\n",
      "\u001b[0;34m        weight (Tensor): the learnable weights of the module of shape (num_embeddings, embedding_dim)\u001b[0m\n",
      "\u001b[0;34m                         initialized from :math:`\\mathcal{N}(0, 1)`\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Shape:\u001b[0m\n",
      "\u001b[0;34m        - Input: :math:`(*)`, IntTensor or LongTensor of arbitrary shape containing the indices to extract\u001b[0m\n",
      "\u001b[0;34m        - Output: :math:`(*, H)`, where `*` is the input shape and :math:`H=\\text{embedding\\_dim}`\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. note::\u001b[0m\n",
      "\u001b[0;34m        Keep in mind that only a limited number of optimizers support\u001b[0m\n",
      "\u001b[0;34m        sparse gradients: currently it's :class:`optim.SGD` (`CUDA` and `CPU`),\u001b[0m\n",
      "\u001b[0;34m        :class:`optim.SparseAdam` (`CUDA` and `CPU`) and :class:`optim.Adagrad` (`CPU`)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. note::\u001b[0m\n",
      "\u001b[0;34m        When :attr:`max_norm` is not ``None``, :class:`Embedding`'s forward method will modify the\u001b[0m\n",
      "\u001b[0;34m        :attr:`weight` tensor in-place. Since tensors needed for gradient computations cannot be\u001b[0m\n",
      "\u001b[0;34m        modified in-place, performing a differentiable operation on ``Embedding.weight`` before\u001b[0m\n",
      "\u001b[0;34m        calling :class:`Embedding`'s forward method requires cloning ``Embedding.weight`` when\u001b[0m\n",
      "\u001b[0;34m        :attr:`max_norm` is not ``None``. For example::\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m            n, d, m = 3, 5, 7\u001b[0m\n",
      "\u001b[0;34m            embedding = nn.Embedding(n, d, max_norm=True)\u001b[0m\n",
      "\u001b[0;34m            W = torch.randn((m, d), requires_grad=True)\u001b[0m\n",
      "\u001b[0;34m            idx = torch.tensor([1, 2])\u001b[0m\n",
      "\u001b[0;34m            a = embedding.weight.clone() @ W.t()  # weight must be cloned for this to be differentiable\u001b[0m\n",
      "\u001b[0;34m            b = embedding(idx) @ W.t()  # modifies weight in-place\u001b[0m\n",
      "\u001b[0;34m            out = (a.unsqueeze(0) + b.unsqueeze(1))\u001b[0m\n",
      "\u001b[0;34m            loss = out.sigmoid().prod()\u001b[0m\n",
      "\u001b[0;34m            loss.backward()\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Examples::\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        >>> # an Embedding module containing 10 tensors of size 3\u001b[0m\n",
      "\u001b[0;34m        >>> embedding = nn.Embedding(10, 3)\u001b[0m\n",
      "\u001b[0;34m        >>> # a batch of 2 samples of 4 indices each\u001b[0m\n",
      "\u001b[0;34m        >>> input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\u001b[0m\n",
      "\u001b[0;34m        >>> embedding(input)\u001b[0m\n",
      "\u001b[0;34m        tensor([[[-0.0251, -1.6902,  0.7172],\u001b[0m\n",
      "\u001b[0;34m                 [-0.6431,  0.0748,  0.6969],\u001b[0m\n",
      "\u001b[0;34m                 [ 1.4970,  1.3448, -0.9685],\u001b[0m\n",
      "\u001b[0;34m                 [-0.3677, -2.7265, -0.1685]],\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m                [[ 1.4970,  1.3448, -0.9685],\u001b[0m\n",
      "\u001b[0;34m                 [ 0.4362, -0.4004,  0.9400],\u001b[0m\n",
      "\u001b[0;34m                 [-0.6431,  0.0748,  0.6969],\u001b[0m\n",
      "\u001b[0;34m                 [ 0.9124, -2.3616,  1.1151]]])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        >>> # example with padding_idx\u001b[0m\n",
      "\u001b[0;34m        >>> embedding = nn.Embedding(10, 3, padding_idx=0)\u001b[0m\n",
      "\u001b[0;34m        >>> input = torch.LongTensor([[0,2,0,5]])\u001b[0m\n",
      "\u001b[0;34m        >>> embedding(input)\u001b[0m\n",
      "\u001b[0;34m        tensor([[[ 0.0000,  0.0000,  0.0000],\u001b[0m\n",
      "\u001b[0;34m                 [ 0.1535, -2.0309,  0.9315],\u001b[0m\n",
      "\u001b[0;34m                 [ 0.0000,  0.0000,  0.0000],\u001b[0m\n",
      "\u001b[0;34m                 [-0.1655,  0.9897,  0.0635]]])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        >>> # example of changing `pad` vector\u001b[0m\n",
      "\u001b[0;34m        >>> padding_idx = 0\u001b[0m\n",
      "\u001b[0;34m        >>> embedding = nn.Embedding(3, 3, padding_idx=padding_idx)\u001b[0m\n",
      "\u001b[0;34m        >>> embedding.weight\u001b[0m\n",
      "\u001b[0;34m        Parameter containing:\u001b[0m\n",
      "\u001b[0;34m        tensor([[ 0.0000,  0.0000,  0.0000],\u001b[0m\n",
      "\u001b[0;34m                [-0.7895, -0.7089, -0.0364],\u001b[0m\n",
      "\u001b[0;34m                [ 0.6778,  0.5803,  0.2678]], requires_grad=True)\u001b[0m\n",
      "\u001b[0;34m        >>> with torch.no_grad():\u001b[0m\n",
      "\u001b[0;34m        ...     embedding.weight[padding_idx] = torch.ones(3)\u001b[0m\n",
      "\u001b[0;34m        >>> embedding.weight\u001b[0m\n",
      "\u001b[0;34m        Parameter containing:\u001b[0m\n",
      "\u001b[0;34m        tensor([[ 1.0000,  1.0000,  1.0000],\u001b[0m\n",
      "\u001b[0;34m                [-0.7895, -0.7089, -0.0364],\u001b[0m\n",
      "\u001b[0;34m                [ 0.6778,  0.5803,  0.2678]], requires_grad=True)\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0m__constants__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'num_embeddings'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'embedding_dim'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'padding_idx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_norm'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                     \u001b[0;34m'norm_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scale_grad_by_freq'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sparse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_embeddings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0membedding_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpadding_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_norm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnorm_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msparse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_embeddings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                 \u001b[0mmax_norm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                 \u001b[0msparse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_weight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                 \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfactory_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dtype'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_embeddings\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32massert\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Padding_idx must be within num_embeddings'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melif\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32massert\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Padding_idx must be within num_embeddings'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mpadding_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_embeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0m_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32massert\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \\\n",
      "                \u001b[0;34m'Shape of weight does not match num_embeddings and embedding_dim'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fill_padding_idx_with_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_fill_padding_idx_with_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{num_embeddings}, {embedding_dim}'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m', padding_idx={padding_idx}'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m', max_norm={max_norm}'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m', norm_type={norm_type}'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m', scale_grad_by_freq={scale_grad_by_freq}'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m', sparse=True'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Creates Embedding instance from given 2-dimensional FloatTensor.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Args:\u001b[0m\n",
      "\u001b[0;34m            embeddings (Tensor): FloatTensor containing weights for the Embedding.\u001b[0m\n",
      "\u001b[0;34m                First dimension is being passed to Embedding as ``num_embeddings``, second as ``embedding_dim``.\u001b[0m\n",
      "\u001b[0;34m            freeze (boolean, optional): If ``True``, the tensor does not get updated in the learning process.\u001b[0m\n",
      "\u001b[0;34m                Equivalent to ``embedding.weight.requires_grad = False``. Default: ``True``\u001b[0m\n",
      "\u001b[0;34m            padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the gradient;\u001b[0m\n",
      "\u001b[0;34m                                         therefore, the embedding vector at :attr:`padding_idx` is not updated during training,\u001b[0m\n",
      "\u001b[0;34m                                         i.e. it remains as a fixed \"pad\".\u001b[0m\n",
      "\u001b[0;34m            max_norm (float, optional): See module initialization documentation.\u001b[0m\n",
      "\u001b[0;34m            norm_type (float, optional): See module initialization documentation. Default ``2``.\u001b[0m\n",
      "\u001b[0;34m            scale_grad_by_freq (boolean, optional): See module initialization documentation. Default ``False``.\u001b[0m\n",
      "\u001b[0;34m            sparse (bool, optional): See module initialization documentation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Examples::\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m            >>> # FloatTensor containing pretrained weights\u001b[0m\n",
      "\u001b[0;34m            >>> weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]])\u001b[0m\n",
      "\u001b[0;34m            >>> embedding = nn.Embedding.from_pretrained(weight)\u001b[0m\n",
      "\u001b[0;34m            >>> # Get embeddings for index 1\u001b[0m\n",
      "\u001b[0;34m            >>> input = torch.LongTensor([1])\u001b[0m\n",
      "\u001b[0;34m            >>> embedding(input)\u001b[0m\n",
      "\u001b[0;34m            tensor([[ 4.0000,  5.1000,  6.3000]])\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \\\n",
      "            \u001b[0;34m'Embeddings parameter is expected to be 2-dimensional'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnum_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0membedding_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0m_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpadding_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnorm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfreeze\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           /opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     Embedding, Embedding"
     ]
    }
   ],
   "source": [
    "torch.nn.Embedding??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#torch.zeros??\n",
    "a = torch.arange(0,10)\n",
    "print(a.shape)\n",
    "a = a.unsqueeze(dim=1)\n",
    "a.shape\n",
    "# torch.unsqueeze??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Dot Product Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "class scaleDotProductAttention(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.softMax = nn.Softmax(dim=-1)\n",
    "\n",
    "\n",
    "    def forward(self,X,q,k,v,mask=None):\n",
    "        batch_size,seq_len,hidden_dim = X.shape\n",
    "        ## 计算Q,K,V\n",
    "        Q = q(X)\n",
    "        K = k(X)\n",
    "        V = v(X)\n",
    "        # Q(batch_size,seq_len,hidden_dim)@K(batch_size,seq_len,hidden_dim)\n",
    "        # 为了相乘，K要进行转置\n",
    "        ##计算attention_weight\n",
    "        attention_weight = Q@K.transpose(-1,-2)/math.sqrt(hidden_dim)\n",
    "        #print(attention_weight.shape)\n",
    "        if mask is not None:\n",
    "            attention_weight = attention_weight.masked_fill(mask==0,float(\"-inf\"))\n",
    "        \n",
    "        attention_weight = self.softMax(attention_weight)\n",
    "        \n",
    "        # 最终得到乘积\n",
    "        attention_scores = attention_weight @ V\n",
    "        return attention_scores\n",
    "\n",
    "X = torch.rand(2,3,4)\n",
    "mask = torch.Tensor([\n",
    "    [1,1,1],\n",
    "    [1,1,0],\n",
    "])\n",
    "\n",
    "Query = nn.Linear(4,4)\n",
    "Key = nn.Linear(4,4)\n",
    "Value = nn.Linear(4,4)\n",
    "\n",
    "# (2,4) (2,)  (2,3,4)\n",
    "# 首先需要加一个dim，然后repeat\n",
    "#print(mask.unsqueeze(dim=1).shape)\n",
    "## 记住mask的shape是(batch_size，seq_len,seq_len)\n",
    "mask = mask.unsqueeze(dim=1).repeat(1,3,1)\n",
    "#print(mask)\n",
    "#print(mask.shape)\n",
    "net = scaleDotProductAttention()\n",
    "out = net(X,Query,Key,Value,mask=mask)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "class scaleDotProductAttentionV2(nn.Module):\n",
    "    def __init__(self,hidden_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.softMax = nn.Softmax(dim=-1)\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self,q,k,v,mask=None):\n",
    "        \n",
    "        ## 计算Q,K,V\n",
    "        Q = q\n",
    "        K = k\n",
    "        V = v\n",
    "        # Q(batch_size,seq_len,hidden_dim)@K(batch_size,seq_len,hidden_dim)\n",
    "        # 为了相乘，K要进行转置\n",
    "        ##计算attention_weight\n",
    "        attention_weight = Q@K.transpose(-1,-2)/math.sqrt(self.hidden_dim)\n",
    "        #print(attention_weight.shape)\n",
    "        if mask is not None:\n",
    "            attention_weight = attention_weight.masked_fill(mask==0,float(\"-inf\"))\n",
    "        \n",
    "        attention_weight = self.softMax(attention_weight)\n",
    "        \n",
    "        # 最终得到乘积\n",
    "        attention_scores = attention_weight @ V\n",
    "        return attention_scores\n",
    "\n",
    "X = torch.rand(2,3,4)\n",
    "mask = torch.Tensor([\n",
    "    [1,1,1],\n",
    "    [1,1,0],\n",
    "])\n",
    "\n",
    "Query = nn.Linear(4,4)\n",
    "Key = nn.Linear(4,4)\n",
    "Value = nn.Linear(4,4)\n",
    "\n",
    "Query = Query(X)\n",
    "Key = Key(X)\n",
    "Value = Value(X)\n",
    "# (2,4) (2,)  (2,3,4)\n",
    "# 首先需要加一个dim，然后repeat\n",
    "#print(mask.unsqueeze(dim=1).shape)\n",
    "## 记住mask的shape是(batch_size，seq_len,seq_len)\n",
    "mask = mask.unsqueeze(dim=1).repeat(1,3,1)\n",
    "#print(mask)\n",
    "#print(mask.shape)\n",
    "net = scaleDotProductAttentionV2(4)\n",
    "out = net(Query,Key,Value,mask=mask)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Multi-head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 然后是根据单头写多头\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,head_nums,hidden_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.head_nums = head_nums\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # 将一段hidden_dim分成多个head\n",
    "        self.Key = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.Query = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.Value = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.singleHeads = scaleDotProductAttentionV2(hidden_dim)\n",
    "        # 这个再看\n",
    "        self.out_proj = nn.Linear(hidden_dim,hidden_dim)\n",
    "        \n",
    "    def forward(self,X,mask=None):\n",
    "        batch_size,seq_len,hidden_dim = X.shape\n",
    "\n",
    "        # 计算Q K V\n",
    "        Q = self.Query(X)\n",
    "        K = self.Key(X)\n",
    "        V = self.Value(X)\n",
    "        # (batch_size,seq_len,hidden_dim)\n",
    "        # =>(batch_size,num_heads,seq_len,hidden_dim//)\n",
    "        # 将计算结果分为多个头\n",
    "\n",
    "        Q = Q.view(batch_size,seq_len,self.head_nums,-1).transpose(-2,-3)\n",
    "        K = K.view(batch_size,seq_len,self.head_nums,-1).permute(0,2,1,3)\n",
    "        V = V.view(batch_size,seq_len,self.head_nums,-1).permute(0,2,1,3)\n",
    "\n",
    "        #对每个头进行传播\n",
    "        out1 = self.singleHeads(Q,K,V,mask)\n",
    "        # 将其重新变成 (batch_size,seq_len,num_heads,hidden_dim)\n",
    "        out1 = out1.transpose(1,2).contiguous()\n",
    "\n",
    "        out2 = out1.view(batch_size,seq_len,-1)\n",
    "        # 连接起来之后，记得proj\n",
    "        output = self.out_proj(out2)\n",
    "        return output\n",
    "\n",
    "head_nums = 2\n",
    "hidden_dim = 4\n",
    "X = torch.rand(2,3,4)\n",
    "# (2,2,3,2)\n",
    "mask = torch.tensor([\n",
    "    [1,1,0],\n",
    "    [1,0,0]\n",
    "])\n",
    "# print(mask.unsqueeze(1))\n",
    "mask = mask.unsqueeze(dim=1).repeat(1,3,1)\n",
    "#print(mask.shape)\n",
    "\n",
    "multihead = MultiHeadAttention(head_nums=head_nums,hidden_dim=hidden_dim)\n",
    "out = multihead(X)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.0000],\n",
      "         [2.0000],\n",
      "         [2.0000],\n",
      "         [2.0000],\n",
      "         [2.0000]],\n",
      "\n",
      "        [[2.0000],\n",
      "         [2.0000],\n",
      "         [2.0000],\n",
      "         [2.0000],\n",
      "         [2.0000]]], grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "class layerNorm(nn.Module):\n",
    "    def __init__(self,hidden_model,eps=1e-12) -> None:\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(hidden_model))\n",
    "        self.beta = nn.Parameter(torch.ones(hidden_model))\n",
    "        self.eps = eps\n",
    "    def forward(self,X):\n",
    "        mean = X.mean(dim=-1,keepdim=True) # keep same size 求和那个dim变为1\n",
    "        var = X.var(dim=-1,keepdim=True)  # keep_dim=False，求和dim就会退化\n",
    "\n",
    "        output = (X-mean)/torch.sqrt(var+self.eps)\n",
    "        #print(\"out1:\",output)\n",
    "        output = self.gamma*output + self.beta\n",
    "        return output\n",
    "\n",
    "X = torch.randn(2,5,4)\n",
    "LN = layerNorm(4)\n",
    "out = LN(X)\n",
    "print(out.mean(dim=-1,keepdim=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position Feed Forward\n",
    "\n",
    "$$\n",
    "    FFN(x) = max(0,xW_1+b_1)W_2 +b_2\n",
    "    \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 64])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self,d_model,d_ff,dropout_rate=0.1) -> None:\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model,d_ff) # 给一个隐藏层的大小即可\n",
    "        self.linear2 = nn.Linear(d_ff,d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(p=dropout_rate)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        out1 = self.linear1(X)\n",
    "        out2 = self.relu(out1)\n",
    "        # 先失活再通过第二个linear\n",
    "        out3 = self.drop(out2)\n",
    "        output = self.linear2(out3)\n",
    "        return output\n",
    "    \n",
    "# 输入输出dim\n",
    "d_model = 64\n",
    "#前馈隐藏层的dim\n",
    "d_ff = 256\n",
    "\n",
    "\n",
    "ffn = FFN(d_model,d_ff)\n",
    "\n",
    "# test\n",
    "X = torch.rand(2,16,64)\n",
    "out = ffn(X)\n",
    "out.shape\n",
    "# 这个也不改变shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
